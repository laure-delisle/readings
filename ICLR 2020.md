# ICLR 2020

The **International Conference on Learning Representations** was scheduled to happen in Addis Ababa, Ethiopia. It was held virtually due to the Covid-19 pandemic. [Videos are available on the ICLR website.](https://iclr.cc/virtual_2020/calendar.html)

## 2020 Vision: Reimagining the Default Settings of Technology & Society
*Prof Ruha Benjamin (Princeton)* - [[video]](https://iclr.cc/virtual_2020/speaker_3.html)

Notes inspired by summary made by *Shakir Mohamed* before the Q&A, and *Timnit Gebru* on Twitter

**Quote of the talk**
> Focus on Deep Learning: computational depth without **historical and sociological depth** is superficial learning 

Three takeaways:
1. Racism constructs systems and produces systems that support it (systematic, diffuse, innovative, productive, in the ivory tower and the tech industry)
2. There is an interplay between race and technology: consider the social impact of technology, as well as the social inputs to technology (and make it feel desirable/inevitable)
3. Imagination is a field of action, an input and output of technology and social order --> most of us live in the imagination of a few: what they imagine are the needs, the usage, the interactions, fairness. 

Prof Benjamin discusses the implications of technology in society, and what happens when we don't take active consideration about questions of structural inequity. How do we develop technology that is just, humane and takes into account historical and sociological depth.

**Historical depth**: ML practicioners need to learn the history of using technology to automatize human destruction ([ref] *IBM and the Holocaust, Edwin Black*), the division of labor diffuses the feeling of responsibility, narrow expertise distracts from the end product and how it can perpetuate structural inequalities.

**Sociological depth**: Digital characters are being predicted and produced, they act as cornerstones of our score society. Scores significantly affect economic/health life chances. How do our systems unwillingly reproduce racial/gender/social disparities. ML practicioners should check for coded bias and an imagined objectivity. Technology can hide the ongoing nature of social domination + enable it under the guise of "progress".

!["Reading list"](https://github.com/laure-delisle/readings/blob/master/imgs/race_critical_code_studies.png)
*Recommended readings and:*

- Advancing Racial Literacy in Tech - Daniels Nkonde Mir. [[pdf]](https://datasociety.net/wp-content/uploads/2019/05/Racial_Literacy_Tech_Final_0522.pdf)
- Ruined by Design - Mike Monteiro.

**Concept: new jim code**. [Engineered inequity, Default discrimination, Coded exposure, Technobenevolence]. Default discrimination: eg ProPublica study, carceral system reinforces and hides racial domination by using questions directly correlated with race and variables affected/structured by racial domination. Coded exposure: tension between ongoing surveillance of racialized population, and digital ignorance by technology (eg facial recognition system used to criminalize or predict face of offender, but not working in daily product to unlock laptop or smile detection). The new jim code concept is similar to Coded gaze (Buolamzini), Racializing surveillance (Browne), Technological redlining (Noble), Technochauvinism (Broussard), Digital Poorhouse (Eubanks).

**Imaginary, hope an creativity**: `Hope is a discipline` (Mariame Kaba)--something we need to practice and build. This should be directed at reshaping our imagination around fostering the common good in the context of living in socities: social contract, institutions, caring for one another. We need `creative resistance`. Example of Covid-19 in Singapore: without the sense of collective good and caring for the most vulnerable, infections skyrocketed (migrant workers in dorms with no sick leave). Some parts of the population get amputated from the collective imaginary, we need to re-include them. They are needed (eg workers) but not currently cared for. In Senegal, low-tech approach + wide care for all turns out to be a more sophisticated response (different idea of the collective good and social imaginary).

**Concept: race**. Prof Benjamin defines the concept of race in 4 parts: symbolic category, based on phenotype and ancestry, varies across times and place, misrecognized as a natural category. Racism is the fatal coupling between power and difference (*Ruth Gilmore, 2002*), racialization is a process.

Often, diversity is superficial instead of substantive: lots of lip-service, downstream, often cosmetic, on website and leaflet. We need substantive diversity in our research/tech problem generation: diversity in how people think about the world and perceive problems to be solved (even before design process, dev).

Change is about collective action, organizing, institutional change. Ultimately, responsibility lies with the individual.

**Current work**: Black skin, white masks: Racism, Vulnerability & Refuting Black Pathology [[video + transcript]](https://aas.princeton.edu/news/black-skin-white-masks-racism-vulnerability-refuting-black-pathology). "Black people are not only trying to survive the pandemic, but also the everyday racism of a sick society."